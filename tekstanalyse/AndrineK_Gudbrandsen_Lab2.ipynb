{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "\n",
    "brown_pos = nltk.pos_tag(brown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = defaultdict(set)\n",
    "freqtag = defaultdict(int)\n",
    "\n",
    "for word, tag in brown_pos:\n",
    "    tags[word].add(tag)\n",
    "    freqtag[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 160733), ('IN', 135982), ('DT', 116201), ('JJ', 81065), ('NNP', 70646)]\n"
     ]
    }
   ],
   "source": [
    "tag_list = [(k, v) for k, v in freqtag.items()]\n",
    "\n",
    "print(sorted(tag_list, key=lambda x: x[1], reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` [('NN', 160733), ('IN', 135982), ('DT', 116201), ('JJ', 81065), ('NNP', 70646)] ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118\n"
     ]
    }
   ],
   "source": [
    "amb_words_list = {k: set(v) for k, v in tags.items() if len(v) > 2} \n",
    "\n",
    "amb_words = len(amb_words_list.keys())\n",
    "\n",
    "print(amb_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```3118```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(set(brown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5622%\n"
     ]
    }
   ],
   "source": [
    "prosent = (float(amb_words) / word_count) * 100\n",
    "\n",
    "print(f\"{prosent:.5}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```5.5622%```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_words = {k:set(v) for k, v in amb_words_list.items() if len(k) > 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you're: {'NNP', 'PDT', 'VBZ', 'VBD', 'RB', 'JJ', 'VB', 'VBN', 'JJR', 'CC', 'VBP', 'PRP', 'NNS', 'NN'}\n",
      "you'll: {'VBN', 'NNP', 'VBZ', 'RB', 'JJ', 'CC', 'VB', 'JJR', 'VBP', 'PRP', 'NNS', 'NN'}\n",
      "You're: {'UH', 'IN', 'PRP$', 'VBZ', 'FW', 'RB', 'VB', 'CC', 'NNP', 'JJ', 'MD', 'NN'}\n",
      "that's: {'IN', 'PDT', 'VBZ', 'VBD', 'FW', 'RB', 'JJ', 'VB', 'VBN', 'VBP', 'NN'}\n",
      "we're: {'IN', 'WP', 'VBZ', 'RB', 'VB', 'JJ', 'VBN', 'VBP', 'NNS', 'NN'}\n"
     ]
    }
   ],
   "source": [
    "for word, tag_list in sorted(dist_words.items(), key=lambda x: len(x[1]), reverse=True)[:5]:\n",
    "    print(\"{}: {}\".format(word, tag_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```you're: {'VBD', 'VBN', 'RB', 'JJ', 'NNP', 'NNS', 'CC', 'VBP', 'JJR', 'PDT', 'PRP', 'VBZ', 'VB', 'NN'}\n",
    "you'll: {'VBN', 'RB', 'JJ', 'CC', 'NNS', 'NNP', 'VBP', 'JJR', 'PRP', 'VBZ', 'VB', 'NN'}\n",
    "You're: {'UH', 'IN', 'RB', 'CC', 'NNP', 'PRP$', 'JJ', 'MD', 'VBZ', 'FW', 'VB', 'NN'}\n",
    "that's: {'VBN', 'IN', 'JJ', 'RB', 'VBP', 'NN', 'PDT', 'VBZ', 'FW', 'VB', 'VBD'}\n",
    "we're: {'VBN', 'IN', 'RB', 'JJ', 'NNS', 'VBP', 'WP', 'VBZ', 'VB', 'NN'}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the word \"that's\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "chosen_word = \"that's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IN', 'PDT', 'VBZ', 'VBD', 'FW', 'RB', 'JJ', 'VB', 'VBN', 'VBP', 'NN'}\n"
     ]
    }
   ],
   "source": [
    "tags_to_find = set(dist_words[chosen_word])\n",
    "print(tags_to_find)\n",
    "sentences = []\n",
    "for sent in brown.sents():\n",
    "    if chosen_word in sent:\n",
    "        m = {w:t for w, t in nltk.pos_tag(sent)}\n",
    "        if m[chosen_word] in tags_to_find:\n",
    "            sentences.append((m[chosen_word], sent))\n",
    "            tags_to_find.remove(m[chosen_word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN - And that's meant as a boost , not a knock .\n",
      "PDT - Comic Gary Morton signed to play the Living Room here Dec. 18 , because that's the only time his heart , Lucille Ball , can come along .\n",
      "VB - He called the Cuban tractor plan an outright blackmail action , and noted that in war `` you can't buy yourself out and that's what we're trying to do '' .\n",
      "VBN - If that's all the Romans did , it's a surprise to me that Rome fell .\n",
      "VBD - If most of them weren't exactly specific -- well , that's the way it is in life , I guess .\n",
      "VBZ - Although he is not graced with the subtleties of romantic technique , that's not what an ex-prize fighter is supposed to have , anyway .\n",
      "JJ - He should have said `` jittery '' , for that's what we are .\n",
      "VBP - Well , whatever you have , that's it ! !\n",
      "IN - Uh huh , we think , looking at them , so that's the Parthenon .\n",
      "RB - `` I'll bet that's as close as you've been to a man since you were a baby '' , Wilson said .\n",
      "FW - He did it because he knows for each guy he puts out of commission that's one less who might take his job away later on .\n"
     ]
    }
   ],
   "source": [
    "for tag, s in sentences:\n",
    "    print(tag, \"-\", \" \".join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)\n",
    "```\n",
    "NN - And that's meant as a boost , not a knock .\n",
    "PDT - Comic Gary Morton signed to play the Living Room here Dec. 18 , because that's the only time his heart , Lucille Ball , can come along .\n",
    "VB - He called the Cuban tractor plan an outright blackmail action , and noted that in war `` you can't buy yourself out and that's what we're trying to do '' .\n",
    "VBN - If that's all the Romans did , it's a surprise to me that Rome fell .\n",
    "VBD - If most of them weren't exactly specific -- well , that's the way it is in life , I guess .\n",
    "VBZ - Although he is not graced with the subtleties of romantic technique , that's not what an ex-prize fighter is supposed to have , anyway .\n",
    "JJ - He should have said `` jittery '' , for that's what we are .\n",
    "VBP - Well , whatever you have , that's it ! !\n",
    "IN - Uh huh , we think , looking at them , so that's the Parthenon .\n",
    "RB - `` I'll bet that's as close as you've been to a man since you were a baby '' , Wilson said .\n",
    "FW - He did it because he knows for each guy he puts out of commission that's one less who might take his job away later on .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)\n",
    "To reduce ambiguity we could look at the words and tags coming before as well as the current word and tag to improve the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Training a tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "from nltk.tag import DefaultTagger, RegexpTagger, UnigramTagger, TrigramTagger, BigramTagger\n",
    "\n",
    "\n",
    "nps_text = Text(nps_chat.words())\n",
    "brown_text = Text(brown.words())\n",
    "\n",
    "nps_tagged = nps_chat.tagged_posts()\n",
    "brown_tagged = brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_most_freq_tag = \"NN\"\n",
    "freqtag = defaultdict(int)\n",
    "for words in nps_tagged:\n",
    "    for word, tag in words:\n",
    "        freqtag[tag] += 1\n",
    "tag_list = [(k, v) for k, v in freqtag.items()]\n",
    "\n",
    "nps_most_freq_tag = sorted(tag_list, key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "brown_word_count = len(brown_text)\n",
    "nps_word_count = len(nps_text)\n",
    "\n",
    "training_sets = [\n",
    "    (brown_tagged[0:int(brown_word_count * 0.9)], nps_tagged[0:int(nps_word_count * 0.1)]),\n",
    "    (brown_tagged[0:int(brown_word_count * 0.5)], nps_tagged[0:int(nps_word_count * 0.5)]),\n",
    "    (nps_tagged[0:int(nps_word_count * 0.9)], brown_tagged[0:int(brown_word_count * 0.1)]),\n",
    "    (nps_tagged[0:int(nps_word_count * 0.5)], brown_tagged[0:int(brown_word_count * 0.5)])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13130472824476916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08871361919573428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000523599887012656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11373028215952011\n"
     ]
    }
   ],
   "source": [
    "brown_default_tagger = DefaultTagger(brown_most_freq_tag)\n",
    "nps_default_tagger = DefaultTagger(nps_most_freq_tag)\n",
    "\n",
    "print(brown_default_tagger.evaluate(brown_tagged))\n",
    "print(brown_default_tagger.evaluate(nps_tagged))\n",
    "print(nps_default_tagger.evaluate(brown_tagged))\n",
    "print(nps_default_tagger.evaluate(nps_tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.13130472824476916\n",
    "* 0.08871361919573428\n",
    "* 0.000523599887012656\n",
    "* 0.11373028215952011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on set 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegExp accuracy: 0.13261984612349575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram accuracy: 0.3662458078516473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram accuracy: 0.36402643519431843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram accuracy: 0.3619550207141448\n",
      "Training on set 1\n",
      "RegExp accuracy: 0.1325483225949789\n",
      "Unigram accuracy: 0.3631415241057543\n",
      "Bigram accuracy: 0.36278604754499\n",
      "Trigram accuracy: 0.36145301044212397\n",
      "Training on set 2\n",
      "RegExp accuracy: 0.2961835768761755\n",
      "Unigram accuracy: 0.5366382131464909\n",
      "Bigram accuracy: 0.5368147558715527\n",
      "Trigram accuracy: 0.5369637407078244\n",
      "Training on set 3\n",
      "RegExp accuracy: 0.2961835768761755\n",
      "Unigram accuracy: 0.5366382131464909\n",
      "Bigram accuracy: 0.5368147558715527\n",
      "Trigram accuracy: 0.5369637407078244\n"
     ]
    }
   ],
   "source": [
    "def train_tagger(training_set, test_set, default_tagger):\n",
    "    backoff = RegexpTagger([\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "        (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
    "        (r'.*able$', 'JJ'),                # adjectives\n",
    "        (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
    "        (r'.*ly$', 'RB'),                  # adverbs\n",
    "        (r'.*s$', 'NNS'),                  # plural nouns\n",
    "        (r'.*ing$', 'VBG'),                # gerunds\n",
    "        (r'.*ed$', 'VBD'),                 # past tense verbs\n",
    "        ],\n",
    "        backoff=default_tagger\n",
    "    )\n",
    "    print(\"     RegExp accuracy:\", backoff.accuracy(test_set))\n",
    "\n",
    "    backoff = UnigramTagger(\n",
    "        training_set,\n",
    "        backoff=backoff\n",
    "    )\n",
    "    print(\"    Unigram accuracy:\", backoff.accuracy(test_set))\n",
    "    \n",
    "    backoff = BigramTagger(\n",
    "        training_set,\n",
    "        backoff=backoff\n",
    "    )\n",
    "    print(\"    Bigram accuracy:\", backoff.accuracy(test_set))\n",
    "       \n",
    "    backoff = TrigramTagger(\n",
    "        training_set,\n",
    "        backoff=backoff\n",
    "    )\n",
    "    print(\"    Trigram accuracy:\", backoff.accuracy(test_set))\n",
    "    \n",
    "    return backoff\n",
    "\n",
    "taggers = list()\n",
    "for i, (training, test) in enumerate(training_sets):\n",
    "    print(f\"Training on set {i}\")\n",
    "    taggers.append(train_tagger(training, test, brown_default_tagger))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Training on set 0\n",
    "    RegExp accuracy: 0.13261984612349575\n",
    "    Unigram accuracy: 0.3662458078516473\n",
    "    Bigram accuracy: 0.36402643519431843\n",
    "    Trigram accuracy: 0.3619550207141448\n",
    "Training on set 1\n",
    "    RegExp accuracy: 0.1325483225949789\n",
    "    Unigram accuracy: 0.3631415241057543\n",
    "    Bigram accuracy: 0.36278604754499\n",
    "    Trigram accuracy: 0.36145301044212397\n",
    "Training on set 2\n",
    "    RegExp accuracy: 0.2961835768761755\n",
    "    Unigram accuracy: 0.5366382131464909\n",
    "    Bigram accuracy: 0.5368147558715527\n",
    "    Trigram accuracy: 0.5369637407078244\n",
    "Training on set 3\n",
    "    RegExp accuracy: 0.2961835768761755\n",
    "    Unigram accuracy: 0.5366382131464909\n",
    "    Bigram accuracy: 0.5368147558715527\n",
    "    Trigram accuracy: 0.5369637407078244\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The taggers are chosen in the order of increased complexity.\n",
    "It seems that running the Ngram taggers in order does not impacy accuracy that much. So each more complex tagger falls back to a simpler one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\n",
    "Chose a 50/50 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag | Prec.  | Recall | F-measure\n",
      "----+--------+--------+-----------\n",
      " UH | 0.9928 | 0.1338 | 0.2358\n",
      "NNP | 0.0000 | 0.0000 | 0.0000\n",
      " VB | 0.6065 | 0.2895 | 0.3920\n",
      " NN | 0.1853 | 0.8520 | 0.3045\n",
      "PRP | 0.0000 | 0.0000 | 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is the tagger with 50/50 split\n",
    "tagger = taggers[1]\n",
    "golden_standard = training_sets[1][1]\n",
    "print(tagger.evaluate_per_tag(golden_standard, truncate=5, sort_by_count=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Tag | Prec.  | Recall | F-measure\n",
    "----+--------+--------+-----------\n",
    " UH | 0.9928 | 0.1338 | 0.2358\n",
    "NNP | 0.0000 | 0.0000 | 0.0000\n",
    " VB | 0.6065 | 0.2895 | 0.3920\n",
    " NN | 0.1853 | 0.8520 | 0.3045\n",
    "PRP | 0.0000 | 0.0000 | 0.0000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline lookup tagger accuracy: 0.253143745834259\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(brown_words)\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words())\n",
    "most_freq_words = fd.most_common(200)\n",
    "likely_tags = {word: cfd[word].max() for (word, _) in most_freq_words}\n",
    "\n",
    "baseline_tagger = UnigramTagger(model=likely_tags, backoff=brown_default_tagger)\n",
    "\n",
    "print(\"Baseline lookup tagger accuracy:\", baseline_tagger.accuracy(golden_standard))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "import random\n",
    "random.seed(101)\n",
    "\n",
    "gutenberg_sents =random.choices(gutenberg.sents(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Separate', 'NN'), ('tall', 'NN'), ('flames', 'NN'), ('shot', 'NN'), ('up', 'RP'), ('and', 'CC'), ('spread', 'NN'), ('out', 'RP'), ('above', 'NN'), ('them', 'PPO'), ('like', 'CS'), ('the', 'AT'), ('fiery', 'NN'), ('cloisters', 'NN'), ('of', 'IN'), ('some', 'DTI'), ('infernal', 'NN'), ('cathedral', 'NN'), (',', ','), ('or', 'CC'), ('like', 'CS'), ('a', 'AT'), ('grove', 'NN'), ('of', 'IN'), ('red', 'NN'), ('tropical', 'NN'), ('trees', 'NN'), ('in', 'IN'), ('the', 'AT'), ('garden', 'NN'), ('of', 'IN'), ('the', 'AT'), ('devil', 'NN'), ('.', '.')]\n",
      "\n",
      "[('8', 'NN'), (':', ':'), ('7', 'NN'), ('And', 'CC'), ('he', 'PPS'), ('put', 'NN'), ('upon', 'IN'), ('him', 'PPO'), ('the', 'AT'), ('coat', 'NN'), (',', ','), ('and', 'CC'), ('girded', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('girdle', 'NN'), (',', ','), ('and', 'CC'), ('clothed', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('robe', 'NN'), (',', ','), ('and', 'CC'), ('put', 'NN'), ('the', 'AT'), ('ephod', 'NN'), ('upon', 'IN'), ('him', 'PPO'), (',', ','), ('and', 'CC'), ('he', 'PPS'), ('girded', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('curious', 'NN'), ('girdle', 'NN'), ('of', 'IN'), ('the', 'AT'), ('ephod', 'NN'), (',', ','), ('and', 'CC'), ('bound', 'NN'), ('it', 'PPS'), ('unto', 'NN'), ('him', 'PPO'), ('therewith', 'NN'), ('.', '.')]\n",
      "\n",
      "[('O', 'NN'), ('to', 'TO'), ('be', 'BE'), ('yielded', 'NN'), ('to', 'TO'), ('you', 'PPSS'), ('whoever', 'NN'), ('you', 'PPSS'), ('are', 'BER'), (',', ','), ('and', 'CC'), ('you', 'PPSS'), ('to', 'TO'), ('be', 'BE'), ('yielded', 'NN'), ('to', 'TO'), ('me', 'PPO'), ('in', 'IN'), ('defiance', 'NN'), ('of', 'IN'), ('the', 'AT'), ('world', 'NN'), ('!', '.')]\n",
      "\n",
      "[('Me', 'NN'), ('thinkes', 'NN'), ('it', 'PPS'), ('is', 'BEZ'), ('like', 'CS'), ('a', 'AT'), ('Weazell', 'NN')]\n",
      "\n",
      "[('2', 'NN'), (':', ':'), ('9', 'NN'), ('He', 'PPS'), ('that', 'CS'), ('saith', 'NN'), ('he', 'PPS'), ('is', 'BEZ'), ('in', 'IN'), ('the', 'AT'), ('light', 'NN'), (',', ','), ('and', 'CC'), ('hateth', 'NN'), ('his', 'PP$'), ('brother', 'NN'), (',', ','), ('is', 'BEZ'), ('in', 'IN'), ('darkness', 'NN'), ('even', 'RB'), ('until', 'NN'), ('now', 'RB'), ('.', '.')]\n",
      "\n",
      "[('He', 'PPS'), ('chose', 'NN'), ('his', 'PP$'), ('place', 'NN'), ('well', 'RB'), (',', ','), ('and', 'CC'), ('waited', 'NN'), ('nearly', 'NN'), ('all', 'ABN'), ('the', 'AT'), ('evening', 'NN'), (',', ','), ('offering', 'NN'), ('his', 'PP$'), ('fossils', 'NN'), ('with', 'IN'), ('great', 'JJ'), ('assiduity', 'NN'), ('to', 'TO'), ('every', 'NN'), ('passenger', 'NN'), (';', '.'), ('but', 'CC'), ('not', '*'), ('one', 'CD'), ('person', 'NN'), ('bought', 'NN'), ('any', 'DTI'), ('.', '.')]\n",
      "\n",
      "[('22', 'NN'), (':', ':'), ('4', 'NN'), ('Thou', 'NN'), ('shalt', 'NN'), ('not', '*'), ('see', 'VB'), ('thy', 'NN'), ('brother', 'NN'), (\"'\", 'NN'), ('s', 'NN'), ('ass', 'NN'), ('or', 'CC'), ('his', 'PP$'), ('ox', 'NN'), ('fall', 'NN'), ('down', 'RP'), ('by', 'IN'), ('the', 'AT'), ('way', 'NN'), (',', ','), ('and', 'CC'), ('hide', 'NN'), ('thyself', 'NN'), ('from', 'IN'), ('them', 'PPO'), (':', ':'), ('thou', 'NN'), ('shalt', 'NN'), ('surely', 'NN'), ('help', 'NN'), ('him', 'PPO'), ('to', 'TO'), ('lift', 'NN'), ('them', 'PPO'), ('up', 'RP'), ('again', 'RB'), ('.', '.')]\n",
      "\n",
      "[('21', 'NN'), (':', ':'), ('20', 'NN'), ('And', 'CC'), ('the', 'AT'), ('families', 'NN'), ('of', 'IN'), ('the', 'AT'), ('children', 'NN'), ('of', 'IN'), ('Kohath', 'NN'), (',', ','), ('the', 'AT'), ('Levites', 'NN'), ('which', 'WDT'), ('remained', 'NN'), ('of', 'IN'), ('the', 'AT'), ('children', 'NN'), ('of', 'IN'), ('Kohath', 'NN'), (',', ','), ('even', 'RB'), ('they', 'PPSS'), ('had', 'HVD'), ('the', 'AT'), ('cities', 'NN'), ('of', 'IN'), ('their', 'PP$'), ('lot', 'NN'), ('out', 'RP'), ('of', 'IN'), ('the', 'AT'), ('tribe', 'NN'), ('of', 'IN'), ('Ephraim', 'NN'), ('.', '.')]\n",
      "\n",
      "[('11', 'NN'), (':', ':'), ('13', 'NN'), ('And', 'CC'), ('his', 'PP$'), ('brethren', 'NN'), (',', ','), ('chief', 'NN'), ('of', 'IN'), ('the', 'AT'), ('fathers', 'NN'), (',', ','), ('two', 'CD'), ('hundred', 'NN'), ('forty', 'NN'), ('and', 'CC'), ('two', 'CD'), (':', ':'), ('and', 'CC'), ('Amashai', 'NN'), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Azareel', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Ahasai', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Meshillemoth', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Immer', 'NN'), (',', ','), ('11', 'NN'), (':', ':'), ('14', 'NN'), ('And', 'CC'), ('their', 'PP$'), ('brethren', 'NN'), (',', ','), ('mighty', 'NN'), ('men', 'NNS'), ('of', 'IN'), ('valour', 'NN'), (',', ','), ('an', 'AT'), ('hundred', 'NN'), ('twenty', 'NN'), ('and', 'CC'), ('eight', 'NN'), (':', ':'), ('and', 'CC'), ('their', 'PP$'), ('overseer', 'NN'), ('was', 'BEDZ'), ('Zabdiel', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('one', 'CD'), ('of', 'IN'), ('the', 'AT'), ('great', 'JJ'), ('men', 'NNS'), ('.', '.')]\n",
      "\n",
      "[('But', 'CC'), ('Bursal', 'NN'), (\"'\", 'NN'), ('s', 'NN'), ('my', 'PP$'), ('witness', 'NN'), ('--', '--')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in baseline_tagger.tag_sents(gutenberg_sents):\n",
    "    print(s)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[('Separate', 'NN'), ('tall', 'NN'), ('flames', 'NN'), ('shot', 'NN'), ('up', 'RP'), ('and', 'CC'), ('spread', 'NN'), ('out', 'RP'), ('above', 'NN'), ('them', 'PPO'), ('like', 'CS'), ('the', 'AT'), ('fiery', 'NN'), ('cloisters', 'NN'), ('of', 'IN'), ('some', 'DTI'), ('infernal', 'NN'), ('cathedral', 'NN'), (',', ','), ('or', 'CC'), ('like', 'CS'), ('a', 'AT'), ('grove', 'NN'), ('of', 'IN'), ('red', 'NN'), ('tropical', 'NN'), ('trees', 'NN'), ('in', 'IN'), ('the', 'AT'), ('garden', 'NN'), ('of', 'IN'), ('the', 'AT'), ('devil', 'NN'), ('.', '.')]\n",
    "\n",
    "[('8', 'NN'), (':', ':'), ('7', 'NN'), ('And', 'CC'), ('he', 'PPS'), ('put', 'NN'), ('upon', 'IN'), ('him', 'PPO'), ('the', 'AT'), ('coat', 'NN'), (',', ','), ('and', 'CC'), ('girded', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('girdle', 'NN'), (',', ','), ('and', 'CC'), ('clothed', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('robe', 'NN'), (',', ','), ('and', 'CC'), ('put', 'NN'), ('the', 'AT'), ('ephod', 'NN'), ('upon', 'IN'), ('him', 'PPO'), (',', ','), ('and', 'CC'), ('he', 'PPS'), ('girded', 'NN'), ('him', 'PPO'), ('with', 'IN'), ('the', 'AT'), ('curious', 'NN'), ('girdle', 'NN'), ('of', 'IN'), ('the', 'AT'), ('ephod', 'NN'), (',', ','), ('and', 'CC'), ('bound', 'NN'), ('it', 'PPS'), ('unto', 'NN'), ('him', 'PPO'), ('therewith', 'NN'), ('.', '.')]\n",
    "\n",
    "[('O', 'NN'), ('to', 'TO'), ('be', 'BE'), ('yielded', 'NN'), ('to', 'TO'), ('you', 'PPSS'), ('whoever', 'NN'), ('you', 'PPSS'), ('are', 'BER'), (',', ','), ('and', 'CC'), ('you', 'PPSS'), ('to', 'TO'), ('be', 'BE'), ('yielded', 'NN'), ('to', 'TO'), ('me', 'PPO'), ('in', 'IN'), ('defiance', 'NN'), ('of', 'IN'), ('the', 'AT'), ('world', 'NN'), ('!', '.')]\n",
    "\n",
    "[('Me', 'NN'), ('thinkes', 'NN'), ('it', 'PPS'), ('is', 'BEZ'), ('like', 'CS'), ('a', 'AT'), ('Weazell', 'NN')]\n",
    "\n",
    "[('2', 'NN'), (':', ':'), ('9', 'NN'), ('He', 'PPS'), ('that', 'CS'), ('saith', 'NN'), ('he', 'PPS'), ('is', 'BEZ'), ('in', 'IN'), ('the', 'AT'), ('light', 'NN'), (',', ','), ('and', 'CC'), ('hateth', 'NN'), ('his', 'PP$'), ('brother', 'NN'), (',', ','), ('is', 'BEZ'), ('in', 'IN'), ('darkness', 'NN'), ('even', 'RB'), ('until', 'NN'), ('now', 'RB'), ('.', '.')]\n",
    "\n",
    "[('He', 'PPS'), ('chose', 'NN'), ('his', 'PP$'), ('place', 'NN'), ('well', 'RB'), (',', ','), ('and', 'CC'), ('waited', 'NN'), ('nearly', 'NN'), ('all', 'ABN'), ('the', 'AT'), ('evening', 'NN'), (',', ','), ('offering', 'NN'), ('his', 'PP$'), ('fossils', 'NN'), ('with', 'IN'), ('great', 'JJ'), ('assiduity', 'NN'), ('to', 'TO'), ('every', 'NN'), ('passenger', 'NN'), (';', '.'), ('but', 'CC'), ('not', '*'), ('one', 'CD'), ('person', 'NN'), ('bought', 'NN'), ('any', 'DTI'), ('.', '.')]\n",
    "\n",
    "[('22', 'NN'), (':', ':'), ('4', 'NN'), ('Thou', 'NN'), ('shalt', 'NN'), ('not', '*'), ('see', 'VB'), ('thy', 'NN'), ('brother', 'NN'), (\"'\", 'NN'), ('s', 'NN'), ('ass', 'NN'), ('or', 'CC'), ('his', 'PP$'), ('ox', 'NN'), ('fall', 'NN'), ('down', 'RP'), ('by', 'IN'), ('the', 'AT'), ('way', 'NN'), (',', ','), ('and', 'CC'), ('hide', 'NN'), ('thyself', 'NN'), ('from', 'IN'), ('them', 'PPO'), (':', ':'), ('thou', 'NN'), ('shalt', 'NN'), ('surely', 'NN'), ('help', 'NN'), ('him', 'PPO'), ('to', 'TO'), ('lift', 'NN'), ('them', 'PPO'), ('up', 'RP'), ('again', 'RB'), ('.', '.')]\n",
    "\n",
    "[('21', 'NN'), (':', ':'), ('20', 'NN'), ('And', 'CC'), ('the', 'AT'), ('families', 'NN'), ('of', 'IN'), ('the', 'AT'), ('children', 'NN'), ('of', 'IN'), ('Kohath', 'NN'), (',', ','), ('the', 'AT'), ('Levites', 'NN'), ('which', 'WDT'), ('remained', 'NN'), ('of', 'IN'), ('the', 'AT'), ('children', 'NN'), ('of', 'IN'), ('Kohath', 'NN'), (',', ','), ('even', 'RB'), ('they', 'PPSS'), ('had', 'HVD'), ('the', 'AT'), ('cities', 'NN'), ('of', 'IN'), ('their', 'PP$'), ('lot', 'NN'), ('out', 'RP'), ('of', 'IN'), ('the', 'AT'), ('tribe', 'NN'), ('of', 'IN'), ('Ephraim', 'NN'), ('.', '.')]\n",
    "\n",
    "[('11', 'NN'), (':', ':'), ('13', 'NN'), ('And', 'CC'), ('his', 'PP$'), ('brethren', 'NN'), (',', ','), ('chief', 'NN'), ('of', 'IN'), ('the', 'AT'), ('fathers', 'NN'), (',', ','), ('two', 'CD'), ('hundred', 'NN'), ('forty', 'NN'), ('and', 'CC'), ('two', 'CD'), (':', ':'), ('and', 'CC'), ('Amashai', 'NN'), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Azareel', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Ahasai', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Meshillemoth', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('Immer', 'NN'), (',', ','), ('11', 'NN'), (':', ':'), ('14', 'NN'), ('And', 'CC'), ('their', 'PP$'), ('brethren', 'NN'), (',', ','), ('mighty', 'NN'), ('men', 'NNS'), ('of', 'IN'), ('valour', 'NN'), (',', ','), ('an', 'AT'), ('hundred', 'NN'), ('twenty', 'NN'), ('and', 'CC'), ('eight', 'NN'), (':', ':'), ('and', 'CC'), ('their', 'PP$'), ('overseer', 'NN'), ('was', 'BEDZ'), ('Zabdiel', 'NN'), (',', ','), ('the', 'AT'), ('son', 'NN'), ('of', 'IN'), ('one', 'CD'), ('of', 'IN'), ('the', 'AT'), ('great', 'JJ'), ('men', 'NNS'), ('.', '.')]\n",
    "\n",
    "[('But', 'CC'), ('Bursal', 'NN'), (\"'\", 'NN'), ('s', 'NN'), ('my', 'PP$'), ('witness', 'NN'), ('--', '--')]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Tagging with probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import MLEProbDist\n",
    "from nltk.util import ngrams\n",
    "# see https://nltk.readthedocs.io/en/latest/api/nltk.html\n",
    "# define distinguishable start/end tuples of tag/word\n",
    "# used to mark sentences\n",
    "START = (\"START\", \"START\")\n",
    "END = (\"END\", \"END\")\n",
    "\n",
    "def get_tags(corpus):\n",
    "    tags_words = []\n",
    "    for sent in corpus.tagged_sents():\n",
    "        tags_words.append(START)\n",
    "        # shorten tags to 2 characters each for simplicity\n",
    "        tags_words.extend([(tag[:2], word) for (word, tag) in sent])\n",
    "        tags_words.append(END)\n",
    "\n",
    "    return tags_words\n",
    "\n",
    "def probDist(corpus, probability_distribution, tag_observation_fn):\n",
    "    tag_words = get_tags(corpus)\n",
    "    tags = [tag for (tag, _) in tag_words]\n",
    "    # conditional frequency distribution over tag/word\n",
    "    cfd_tagwords = nltk.ConditionalFreqDist(tag_words)\n",
    "    cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, probability_distribution)\n",
    "    # conditional frequency distribution of observations:\n",
    "    cfd_tags = nltk.ConditionalFreqDist(tag_observation_fn(tags))\n",
    "    cpd_tags = nltk.ConditionalProbDist(cfd_tags, probability_distribution)\n",
    "    \n",
    "    return cpd_tagwords, cpd_tags\n",
    "\n",
    "def task3a():\n",
    "    corpus = brown\n",
    "    # maximum likelihood estimate to create a probability distribution \n",
    "    probability_distribution = nltk.MLEProbDist\n",
    "    # a function to create tag observations. Hint: can we observe anything with unigrams?\n",
    "    tag_observation_fn = lambda tags: ngrams(tags, 2)\n",
    "    return probDist(corpus, probability_distribution, tag_observation_fn)\n",
    "    \n",
    "def prettify(prob):\n",
    "    return \"{}%\".format(round(prob * 100, 4))\n",
    "    \n",
    "def task3b():\n",
    "    tagwords, tags = task3a()\n",
    "    prob_verb_is_run = tagwords[\"VB\"].prob(\"run\")  # IMPLEMENT\n",
    "    prob_v_follows_p = tags[\"PP\"].prob(\"VB\")  # IMPLEMENT\n",
    "    print(\"Prob. of a Verb(VB) being 'run' is\", prettify(prob_verb_is_run))\n",
    "    print(\"Prob. of a Preposition(PP) being followed by a Verb(VB) is\", prettify(prob_v_follows_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of a Verb(VB) being 'run' is 0.1329%\n",
      "Prob. of a Preposition(PP) being followed by a Verb(VB) is 25.1591%\n"
     ]
    }
   ],
   "source": [
    "task3b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "Prob. of a Verb(VB) being 'run' is 0.1329%\n",
    "\n",
    "Prob. of a Preposition(PP) being followed by a Verb(VB) is 25.1591%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagwords, tags = task3a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:\n",
      "   time, man, Af, years, way, people, men, world, life, year\n",
      "VB:\n",
      "   said, made, make, see, get, know, came, used, go, come\n",
      "JJ:\n",
      "   new, such, own, good, great, New, old, American, small, long\n"
     ]
    }
   ],
   "source": [
    "for tag in [\"NN\", \"VB\", \"JJ\"]:\n",
    "    print(tag + \":\\n  \", \", \".join(map(lambda e: e[0], tagwords[tag].freqdist().most_common(10))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\n",
    "```\n",
    "NN:\n",
    "   time, man, Af, years, way, people, men, world, life, year\n",
    "VB:\n",
    "   said, made, make, see, get, know, came, used, go, come\n",
    "JJ:\n",
    "   new, such, own, good, great, New, old, American, small, long\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"I can code some code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)\n",
    "\n",
    "I am not sure how to solve this one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
