{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "We'll use this lab as an experiment of using a single file where you fill in codeblocks where necessary. They will be available as .py and .ipynb. Using the latter, or Jupyter Notebook, is highly recommended, as it provides substantially better feedback.\n",
    "\n",
    "\n",
    "Provide your outputs in a simple report, along with textual answers.\n",
    "\n",
    "\n",
    "The idea behind this format is to clarify what sort of output is required, as all answers run on tests based in the `tests.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "# feel free to import from modules of sklearn and nltk later\n",
    "# e.g., from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Gender detection of names\n",
    "In NLTK you'll find the corpus `corpus.names`. A set of 5000 male and 3000 female names.\n",
    "1) Select a ratio of train/test data (based on experiences from previous labs perhaps?)\n",
    "2) Build a feature extractor function\n",
    "3) Build two classifiers:\n",
    "    - Decision tree\n",
    "    - Na√Øve bayes\n",
    "    \n",
    "Finally, write code to evaluate the classifiers. Explain your results, and what do you think would change if you altered your feature extractor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderDataset:\n",
    "    def __init__(self):\n",
    "        self.names = nltk.corpus.names\n",
    "        self.data = None \n",
    "        self.build()\n",
    "\n",
    "    def make_labels(self, gender):\n",
    "        return [(n, gender) for n in self.names.words(gender + \".txt\")]\n",
    "    \n",
    "    def build(self):\n",
    "        self.data = self.make_labels(\"female\")\n",
    "        self.data.extend(self.make_labels(\"male\"))\n",
    "    \n",
    "    def split(self, ratio):\n",
    "        return train_test_split(self.data, test_size=ratio, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.model = self.classifier.train(train_set)\n",
    "        \n",
    "    def test(self, data):\n",
    "        return nltk.classify.accuracy(self.model, data)\n",
    "    \n",
    "    def train_and_evaluate(self, train, test):\n",
    "        self.train(train)\n",
    "        return self.test(test)\n",
    "        \n",
    "    def show_features(self):\n",
    "        # OPTIONAL\n",
    "        pass\n",
    "\n",
    "                                 \n",
    "class FeatureExtractor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.features = []  \n",
    "        \n",
    "        self.build()\n",
    "                 \n",
    "    @staticmethod\n",
    "    def text_to_features(name):\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"last_letter\": name[-1],\n",
    "            \"first_letter\": name[0],\n",
    "        }\n",
    "    \n",
    "    def build(self):\n",
    "        for name, tag in self.data:\n",
    "            self.features.append((FeatureExtractor.text_to_features(name), tag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should achieve an accuracy of well above 70%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: decision_tree\tAccuracy: 0.6124538435716683\n",
      "Model: naive_bayes\tAccuracy: 0.7554548506210138\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.75  # TODO: modify\n",
    "train, test = GenderDataset().split(ratio=split_ratio)\n",
    "\n",
    "classifiers = {\n",
    "    \"decision_tree\": Classifier(DecisionTreeClassifier),\n",
    "    \"naive_bayes\": Classifier(NaiveBayesClassifier), \n",
    "}\n",
    "\n",
    "train_set = FeatureExtractor(train).features\n",
    "test_set = FeatureExtractor(test).features\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    acc = classifier.train_and_evaluate(train_set, test_set)\n",
    "    print(\"Model: {}\\tAccuracy: {}\".format(name, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: decision_tree\t   Accuracy: 0.6124538435716683 \n",
    "\n",
    "Model: naive_bayes\t       Accuracy: 0.7554548506210138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Spam or ham\n",
    "Spam or ham is referred to a mail being spam or regular (\"ham\"). Follow the instructions and implement the `TODOs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\n",
    "    'spam.csv',\n",
    "    usecols=[\"v1\", \"v2\"],\n",
    "    encoding=\"latin-1\"\n",
    ").rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "\n",
    "print(spam.label.value_counts())\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ham     4825\n",
    "spam     747\n",
    "Name: label, dtype: int64\n",
    "label\ttext\n",
    "0\tham\tGo until jurong point, crazy.. Available only ...\n",
    "1\tham\tOk lar... Joking wif u oni...\n",
    "2\tspam\tFree entry in 2 a wkly comp to win FA Cup fina...\n",
    "3\tham\tU dun say so early hor... U c already then say...\n",
    "4\tham\tNah I don't think he goes to usf, he lives aro...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelmapping = {\n",
    "    \"ham\": 0,\n",
    "    \"spam\": 1\n",
    "    }\n",
    "\n",
    "spam.label = spam.label.apply(labelmapping.get)\n",
    "spam.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0    4825\n",
    "1     747\n",
    "Name: label, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self, text):\n",
    "        self.text = word_tokenize(text) \n",
    "        self.stemmer = PorterStemmer() \n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.lem = WordNetLemmatizer()\n",
    "    \n",
    " \n",
    "    def lowercase(self):\n",
    "        \"\"\"\n",
    "        Create small functions to replace your tokens (self.text)\n",
    "        iteratively. Such as a lowercase function.\n",
    "        \"\"\"\n",
    "        self.text = [w.lower() for w in self.text]\n",
    "\n",
    "    def clean(self):\n",
    "        self.lowercase()\n",
    "        self.text = [word for word in self.text if word not in self.stopwords]\n",
    "        self.text = [self.stemmer.stem(word) for word in self.text]\n",
    "        self.text = [self.lem.lemmatize(word) for word in self.text]\n",
    "        return \" \".join(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean = lambda text: TextCleaner(text).clean()\n",
    "spam.text = spam.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point , crazi .. avail bugi n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say earli hor ... u c alreadi say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah n't think goe usf , live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  go jurong point , crazi .. avail bugi n great ...\n",
       "1      0                      ok lar ... joke wif u oni ...\n",
       "2      1  free entri 2 wkli comp win fa cup final tkt 21...\n",
       "3      0        u dun say earli hor ... u c alreadi say ...\n",
       "4      0         nah n't think goe usf , live around though"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "label\ttext\n",
    "0\t0\tgo jurong point , crazi .. avail bugi n great ...\n",
    "1\t0\tok lar ... joke wif u oni ...\n",
    "2\t1\tfree entri 2 wkli comp win fa cup final tkt 21...\n",
    "3\t0\tu dun say earli hor ... u c alreadi say ...\n",
    "4\t0\tnah n't think goe usf , live around though\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "split_ratio = 0.50 \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    spam.text, spam.label, test_size=split_ratio, random_state=4310)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "if classifier:\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data) # TODO apply the transformation from the vectorizer to test data \n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)\n",
    "\n",
    "def print_examples(data, probs, label1, label2, n=10):\n",
    "    percent = lambda x: \"{}%\".format(round(x*100, 1))\n",
    "\n",
    "    for text, pred in list(zip(data, probs))[:n]:\n",
    "        print(\"{}\\n{}: {} / {}: {}\\n{}\".format(\n",
    "            text,\n",
    "            label1,\n",
    "            percent(pred[0]),\n",
    "            label2,\n",
    "            percent(pred[1]),\n",
    "            \"-\" * 100  # to print a line\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world famamu ....\n",
      "ham: 98.1% / spam: 1.9%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\\aww must nearli dead ! well jez iscom todo workand whilltak forev ! \\ '' ''\n",
      "ham: 98.9% / spam: 1.1%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "babe . hope ok . shit night sleep . fell asleep 5.i√•√µm knacker i√•√µm dread work tonight . thou upto tonight . x\n",
      "ham: 100.0% / spam: 0.0%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "thank . like well ...\n",
      "ham: 99.9% / spam: 0.1%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'m read text sent . meant joke . read light\n",
      "ham: 99.8% / spam: 0.2%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "oki √¨_ wan meet bishan ? co bishan . 'm drive today .\n",
      "ham: 100.0% / spam: 0.0%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "smile pleasur smile pain smile troubl pour like rain smile sum1 hurt u smile becoz someon still love see u smile ! !\n",
      "ham: 100.0% / spam: 0.0%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hi : ) ct employe ?\n",
      "ham: 95.7% / spam: 4.3%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "c movi juz last minut decis mah . juz watch 2 lar tot √¨_ interest .\n",
      "ham: 100.0% / spam: 0.0%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "; - ) ok . feel like john lennon .\n",
      "ham: 100.0% / spam: 0.0%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[2395   15]\n",
      " [  31  345]]\n",
      "Recall=0.92\n",
      "Precision=0.96\n"
     ]
    }
   ],
   "source": [
    "if classifier:\n",
    "    y_probas = predict(classifier, vectorizer, X_test, all_predictions=True)\n",
    "    print_examples(X_test, y_probas, \"ham\", \"spam\")\n",
    "\n",
    "    y_pred = predict(classifier, vectorizer, X_test)\n",
    "    # TODO display a confusion matrix on the test set vs predictions\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "\n",
    "    # show precision and recall in a confusion matrix\n",
    "    tn, fp, fn, tp = confusion_mat.ravel()\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    print(\"Recall={}\\nPrecision={}\".format(round(recall, 2), round(precision, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "world famamu ....\n",
    "ham: 98.1% / spam: 1.9%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\\aww must nearli dead ! well jez iscom todo workand whilltak forev ! \\ '' ''\n",
    "ham: 98.9% / spam: 1.1%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "babe . hope ok . shit night sleep . fell asleep 5.i√•√µm knacker i√•√µm dread work tonight . thou upto tonight . x\n",
    "ham: 100.0% / spam: 0.0%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "thank . like well ...\n",
    "ham: 99.9% / spam: 0.1%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "'m read text sent . meant joke . read light\n",
    "ham: 99.8% / spam: 0.2%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "oki √¨_ wan meet bishan ? co bishan . 'm drive today .\n",
    "ham: 100.0% / spam: 0.0%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "smile pleasur smile pain smile troubl pour like rain smile sum1 hurt u smile becoz someon still love see u smile ! !\n",
    "ham: 100.0% / spam: 0.0%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "hi : ) ct employe ?\n",
    "ham: 95.7% / spam: 4.3%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "c movi juz last minut decis mah . juz watch 2 lar tot √¨_ interest .\n",
    "ham: 100.0% / spam: 0.0%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "; - ) ok . feel like john lennon .\n",
    "ham: 100.0% / spam: 0.0%\n",
    "----------------------------------------------------------------------------------------------------\n",
    "[[2395   15]\n",
    " [  31  345]]\n",
    "Recall=0.92\n",
    "Precision=0.96\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 3 - Word features\n",
    "Word features can be very useful for performing document classification, since the words that appear in a document give a strong indication of what its semantic content is. However, many words occur very infrequently, and some of the most informative words in a document may never have occurred in our training data. One solution is to make use of a lexicon, which describes how different words relate to each other.\n",
    "\n",
    "Your task:\n",
    "- Use the WordNet lexicon and augment the movie review document classifier (See NLTK book, Ch. 6, section 1.3) to use features that generalize the words that appear in a document, making it more likely that they will match words found in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download wordnet and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "# TODO: implement a function that returns a synonym for \"word\" if available, otherwise return the word itself\n",
    "def word_to_syn(word):\n",
    "    synonyms = wn.synsets(word)\n",
    "    lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    return word if len(lemmas) == 0 else random.choice(list(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is from Ch. 6, sec. 1.3, with slight modifications\n",
    "note that word_to_syn(word) (from the above implementation)\n",
    "is in the beginning of the following function\n",
    "\"\"\"\n",
    "documents = [([word_to_syn(word) for word in list(movie_reviews.words(fileid))], category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "n_most_freq = 2000\n",
    "word_features = list(all_words)[:n_most_freq]\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "\n",
    "split_ratio = 0.75 \n",
    "train_set, test_set = train_test_split(featuresets, test_size=split_ratio)\n",
    "\n",
    "\n",
    "classifier = NaiveBayesClassifier\n",
    "model = classifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: return a flattened list of input words and their lemmas\n",
    "def synset_expansion(words) -> list:\n",
    "    allwords = []\n",
    "    for word in words:\n",
    "        synonyms = wn.synsets(word)\n",
    "        lemmas = set(map(str.lower,chain.from_iterable([word.lemma_names() for word in synonyms])))\n",
    "        lemmas.add(word)\n",
    "        allwords.extend(lemmas)\n",
    "    return allwords\n",
    "\n",
    "expanded_word_features = synset_expansion(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assertions to test your code :-)\n",
    "assert sorted(synset_expansion([\"pc\"])) == [\"microcomputer\", \"pc\", \"personal_computer\"]\n",
    "assert sorted(synset_expansion([\"programming\", \"coder\"])) == [\n",
    "    'coder',\n",
    "    'computer_programing',\n",
    "    'computer_programmer',\n",
    "    'computer_programming',\n",
    "    'program',\n",
    "    'programing',\n",
    "    'programme',\n",
    "    'programmer',\n",
    "    'programming',\n",
    "    'scheduling',\n",
    "    'software_engineer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(mulan) = True              pos : neg    =      8.2 : 1.0\n",
      "      contains(touching) = True              pos : neg    =      7.6 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.6 : 1.0\n",
      "    contains(determined) = True              pos : neg    =      7.5 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      7.5 : 1.0\n",
      "Accuracy:  0.685\n"
     ]
    }
   ],
   "source": [
    "doc_featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "doc_train_set, doc_test_set = train_test_split(doc_featuresets, test_size=0.1)\n",
    "\n",
    "doc_model = model.train(doc_train_set)\n",
    "doc_model.show_most_informative_features(5)\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(doc_model, doc_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Informative Features\n",
    "         contains(mulan) = True              pos : neg    =      8.2 : 1.0\n",
    "      contains(touching) = True              pos : neg    =      7.6 : 1.0\n",
    "        contains(seagal) = True              neg : pos    =      7.6 : 1.0\n",
    "    contains(determined) = True              pos : neg    =      7.5 : 1.0\n",
    "   contains(wonderfully) = True              pos : neg    =      7.5 : 1.0\n",
    "Accuracy:  0.685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_features(reviews):\n",
    "    review_words = set(reviews)\n",
    "    features = {}\n",
    "    for word in expanded_word_features:\n",
    "        if word not in word_features:\n",
    "            features['synset({})'.format(word)] = (word in review_words)\n",
    "        features['contains({})'.format(word)] = (word in review_words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: do you see any issues with including the synsets? Experiment a bit with different words and verify your ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "  contains(pudding_head) = True              neg : pos    =     13.3 : 1.0\n",
      "    synset(pudding_head) = True              neg : pos    =     13.3 : 1.0\n",
      "      contains(touching) = True              pos : neg    =     12.7 : 1.0\n",
      "   contains(pudden-head) = True              neg : pos    =     12.6 : 1.0\n",
      "     synset(pudden-head) = True              neg : pos    =     12.6 : 1.0\n",
      "       contains(declare) = True              pos : neg    =     11.4 : 1.0\n",
      "         synset(declare) = True              pos : neg    =     11.4 : 1.0\n",
      "       contains(misfire) = True              neg : pos    =     11.2 : 1.0\n",
      "         contains(worst) = True              neg : pos    =     11.2 : 1.0\n",
      "         synset(misfire) = True              neg : pos    =     11.2 : 1.0\n",
      "Accuracy:  0.695\n"
     ]
    }
   ],
   "source": [
    "# warning: this may take some time to run\n",
    "lex_featuresets = [(lexicon_features(d), c) for (d, c) in documents]\n",
    "lex_train_set, lex_test_set = train_test_split(lex_featuresets, test_size=0.1)\n",
    "lex_model = model.train(lex_train_set)  # the same classifier as you defined above\n",
    "lex_model.show_most_informative_features()\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(lex_model, lex_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Informative Features\n",
    "  contains(pudding_head) = True              neg : pos    =     13.3 : 1.0\n",
    "    synset(pudding_head) = True              neg : pos    =     13.3 : 1.0\n",
    "      contains(touching) = True              pos : neg    =     12.7 : 1.0\n",
    "   contains(pudden-head) = True              neg : pos    =     12.6 : 1.0\n",
    "     synset(pudden-head) = True              neg : pos    =     12.6 : 1.0\n",
    "       contains(declare) = True              pos : neg    =     11.4 : 1.0\n",
    "         synset(declare) = True              pos : neg    =     11.4 : 1.0\n",
    "       contains(misfire) = True              neg : pos    =     11.2 : 1.0\n",
    "         contains(worst) = True              neg : pos    =     11.2 : 1.0\n",
    "         synset(misfire) = True              neg : pos    =     11.2 : 1.0\n",
    "Accuracy:  0.695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 4 -- Experimentation\n",
    "This exercise is largely open to experiment with and testing your skills thus far!\n",
    "Large websites are an ideal place to look for large corpora of natural language. In this exercise, you're free to implement what you've learned on real-world data, mined from youtube (see `youtube_data`). Reuse classes defined earlier on in the exercise if you want.\n",
    "\n",
    "The only requirement here is to **use a classifier not previously used in the exercise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to classify videos with disabled comments.\n",
    "yt_data = pd.read_csv(\n",
    "    'youtube_data/videos.csv',\n",
    "    usecols=[\"comments_disabled\", \"description\"],\n",
    ").rename(columns={\"comments_disabled\": \"label\", \"description\": \"text\"})\n",
    "yt_data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_data.label = yt_data.label.apply(lambda x: 1 if x else 0) # your transformation goes here\n",
    "yt_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = lambda text: TextCleaner(text).clean()\n",
    "yt_data.text = yt_data.text.apply(clean)\n",
    "\n",
    "yt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "split_ratio = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    spam.text, spam.label, test_size=split_ratio, random_state=4310)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "classifier = ComplementNB()\n",
    "if classifier:\n",
    "    classifier.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data).toarray() # TODO apply the transformation from the vectorizer to test data \n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier:\n",
    "    y_probas = predict(classifier, vectorizer, X_test, all_predictions=True)\n",
    "    print_examples(X_test, y_probas, \"comment\", \"no_comment\")\n",
    "\n",
    "    y_pred = predict(classifier, vectorizer, X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_mat.ravel()\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    print(\"Recall={}\\nPrecision={}\".format(round(recall, 2), round(precision, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
